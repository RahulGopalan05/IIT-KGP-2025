{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPJpI1RbM1eMcjS8oMB9aZo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a0ba8dde1c6646ec910c532e892ba415":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b28346374fa4ad582243b00ec4702ab","IPY_MODEL_4db2f7a338b94b8eaa078872538a9913","IPY_MODEL_adddf993a09f432081f22c2a66f9181b"],"layout":"IPY_MODEL_b5e1f351df83452daf5b2d0d10280ce7"}},"3b28346374fa4ad582243b00ec4702ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ea2e73cf8fd4e698c45695abb8522ea","placeholder":"​","style":"IPY_MODEL_9dd6553a9c334078a1b4c2de6c89d69d","value":"config.json: 100%"}},"4db2f7a338b94b8eaa078872538a9913":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f36b6ccf150943f5af9d3302061de0ec","max":1404,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4fe3df4e5b934452b85f492262ebc5e4","value":1404}},"adddf993a09f432081f22c2a66f9181b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d87082c6493643f6909d55a70eca89f6","placeholder":"​","style":"IPY_MODEL_8d5ad049b45048038207eda112819843","value":" 1.40k/1.40k [00:00&lt;00:00, 63.3kB/s]"}},"b5e1f351df83452daf5b2d0d10280ce7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ea2e73cf8fd4e698c45695abb8522ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dd6553a9c334078a1b4c2de6c89d69d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f36b6ccf150943f5af9d3302061de0ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fe3df4e5b934452b85f492262ebc5e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d87082c6493643f6909d55a70eca89f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d5ad049b45048038207eda112819843":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35e1183cb0b641839d0dc363e29a39d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad6fd4c36d694b3daf827ed1a5912743","IPY_MODEL_5082d36da22b45a6bf7cbe7e907905c5","IPY_MODEL_19e394bb9dd4468b9f44d12102dfca0d"],"layout":"IPY_MODEL_e2f4a9fbb98d4250aad35dc264bbb706"}},"ad6fd4c36d694b3daf827ed1a5912743":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4fbae0377be43e883ae3bc12962b84a","placeholder":"​","style":"IPY_MODEL_3def0fd5ed9a4fe8912a417f2cb56a26","value":"model.safetensors: 100%"}},"5082d36da22b45a6bf7cbe7e907905c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9634cb7bf7b745b2a98e9ce4e2113a3e","max":990345061,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59f2d02f420d43029d670383a9970bee","value":990345061}},"19e394bb9dd4468b9f44d12102dfca0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c54297a148294564a830eb43d0f2c4b1","placeholder":"​","style":"IPY_MODEL_44e18f28daa54b36bb32e521c8a65338","value":" 990M/990M [00:08&lt;00:00, 243MB/s]"}},"e2f4a9fbb98d4250aad35dc264bbb706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4fbae0377be43e883ae3bc12962b84a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3def0fd5ed9a4fe8912a417f2cb56a26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9634cb7bf7b745b2a98e9ce4e2113a3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59f2d02f420d43029d670383a9970bee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c54297a148294564a830eb43d0f2c4b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44e18f28daa54b36bb32e521c8a65338":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"661254c18a8246c199749007b058964f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21eb8eb96fdb47a8ba794121bf02323a","IPY_MODEL_5abdd351905e441da9bdbad72a894b17","IPY_MODEL_66712e90d0064cb0847eec7b6ffc337b"],"layout":"IPY_MODEL_dd2b864e6b174994831b3785c32acf05"}},"21eb8eb96fdb47a8ba794121bf02323a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cac865ba8db49a2a669c82326cd5ee2","placeholder":"​","style":"IPY_MODEL_2657c9f61911473bb22b1a1ce0adcf17","value":"generation_config.json: 100%"}},"5abdd351905e441da9bdbad72a894b17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3aa893f761ca481fbae4443338114c23","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f0ceced2016466fb0b819d7ae31d489","value":147}},"66712e90d0064cb0847eec7b6ffc337b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcaed63142e1476b8eff4ab36eedfe08","placeholder":"​","style":"IPY_MODEL_7c648ffd1b0947f9b609f829c2d38822","value":" 147/147 [00:00&lt;00:00, 8.68kB/s]"}},"dd2b864e6b174994831b3785c32acf05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cac865ba8db49a2a669c82326cd5ee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2657c9f61911473bb22b1a1ce0adcf17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3aa893f761ca481fbae4443338114c23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f0ceced2016466fb0b819d7ae31d489":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcaed63142e1476b8eff4ab36eedfe08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c648ffd1b0947f9b609f829c2d38822":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c9ff15a5d5241258cb849a9be759189":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54b33c924ee941c0961406b87862dfb5","IPY_MODEL_97c92f024a7d4f499b2b02fc9e36fad9","IPY_MODEL_8b0ebd4a25614e8e92c84d0b5f99839f"],"layout":"IPY_MODEL_5b97871f23b44f3592be9a0922432295"}},"54b33c924ee941c0961406b87862dfb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e000ef3ca6d44bb9a5c4c340d0de76fb","placeholder":"​","style":"IPY_MODEL_1fe82d4b328845c0987b16cf45cf3383","value":"tokenizer_config.json: 100%"}},"97c92f024a7d4f499b2b02fc9e36fad9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf38445015514fdda15a26f674311c2f","max":2537,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8202a6de43ac4692962f499e18e8165c","value":2537}},"8b0ebd4a25614e8e92c84d0b5f99839f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_376c1336105e40478f52487d13e74d73","placeholder":"​","style":"IPY_MODEL_82e41547e60e475782e9663a402497f6","value":" 2.54k/2.54k [00:00&lt;00:00, 203kB/s]"}},"5b97871f23b44f3592be9a0922432295":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e000ef3ca6d44bb9a5c4c340d0de76fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fe82d4b328845c0987b16cf45cf3383":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf38445015514fdda15a26f674311c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8202a6de43ac4692962f499e18e8165c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"376c1336105e40478f52487d13e74d73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82e41547e60e475782e9663a402497f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32f9c3e6c2df431d93d4ebf9095af0c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a82cf3769104ca98d8ed81be6d30f17","IPY_MODEL_a5301d236b594b0eabc4be6374915bdc","IPY_MODEL_fc6636acc6cd4b01b23e31da90ad2d70"],"layout":"IPY_MODEL_e5a0869e73b241e99e6d397ad77a2620"}},"1a82cf3769104ca98d8ed81be6d30f17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed1ace2e997445b78165581e4ffa7751","placeholder":"​","style":"IPY_MODEL_18f4243abc724103a963741045b2f3a2","value":"spiece.model: 100%"}},"a5301d236b594b0eabc4be6374915bdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdf7137320ec4af9879c58088b5f5ab6","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf196d5f57864586adc988dbd2a57a24","value":791656}},"fc6636acc6cd4b01b23e31da90ad2d70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01a1a5a68e4f45f6aeacbb0711cccfcb","placeholder":"​","style":"IPY_MODEL_6ceb0661d55b4dfaa931c917d865aec3","value":" 792k/792k [00:00&lt;00:00, 29.0MB/s]"}},"e5a0869e73b241e99e6d397ad77a2620":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed1ace2e997445b78165581e4ffa7751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f4243abc724103a963741045b2f3a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdf7137320ec4af9879c58088b5f5ab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf196d5f57864586adc988dbd2a57a24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01a1a5a68e4f45f6aeacbb0711cccfcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ceb0661d55b4dfaa931c917d865aec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afc1bbbe574f40c0aa99e92498b3062f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_914b6ecb1b9b4fcbaccf8013340caa82","IPY_MODEL_36766b8751534f309ad9e7f483cdafbe","IPY_MODEL_00ad5a8479654528a18b3b90f1c299d4"],"layout":"IPY_MODEL_bbea0bf76fd0414b832b065faec5c9c3"}},"914b6ecb1b9b4fcbaccf8013340caa82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54d02d0b1191490ca76dc4eb9a834956","placeholder":"​","style":"IPY_MODEL_3713051e481f4fb785bc9291ca7cc701","value":"tokenizer.json: 100%"}},"36766b8751534f309ad9e7f483cdafbe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_467291599826467ea4965afbd94a2f1d","max":2424064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_109fa126706a46469ee4ac4ceb92dc52","value":2424064}},"00ad5a8479654528a18b3b90f1c299d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce0359c275404c838ecf9d9c30f44754","placeholder":"​","style":"IPY_MODEL_922cde49f8194be88a1f652908b0fd9b","value":" 2.42M/2.42M [00:00&lt;00:00, 9.96MB/s]"}},"bbea0bf76fd0414b832b065faec5c9c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54d02d0b1191490ca76dc4eb9a834956":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3713051e481f4fb785bc9291ca7cc701":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"467291599826467ea4965afbd94a2f1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"109fa126706a46469ee4ac4ceb92dc52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce0359c275404c838ecf9d9c30f44754":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"922cde49f8194be88a1f652908b0fd9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e586c051a7e49d4a8464f1a74a8393c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b9ed184fdf5436186ee590dfca7b2e9","IPY_MODEL_dfd73b6968434c3f92a28d95c2739eb6","IPY_MODEL_40ec16594cc74a8d9e1cdd93355a82d1"],"layout":"IPY_MODEL_23f7bb2cdbeb400fa96eaa71247e22c2"}},"7b9ed184fdf5436186ee590dfca7b2e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_752bb933b9e04e3ea80188b250bd4202","placeholder":"​","style":"IPY_MODEL_cae919e8e9ed4e37a59818a6fce25fec","value":"special_tokens_map.json: 100%"}},"dfd73b6968434c3f92a28d95c2739eb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79d77be0dad245b685353783e32faf59","max":2201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e6a056a44324dca8b89fa99884acb55","value":2201}},"40ec16594cc74a8d9e1cdd93355a82d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41ee7cbf144d499c83677f4fc1ac64b3","placeholder":"​","style":"IPY_MODEL_905fc9e19838460e83ae78f6ca1de355","value":" 2.20k/2.20k [00:00&lt;00:00, 135kB/s]"}},"23f7bb2cdbeb400fa96eaa71247e22c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"752bb933b9e04e3ea80188b250bd4202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cae919e8e9ed4e37a59818a6fce25fec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79d77be0dad245b685353783e32faf59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e6a056a44324dca8b89fa99884acb55":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41ee7cbf144d499c83677f4fc1ac64b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"905fc9e19838460e83ae78f6ca1de355":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rq999MQ0oYuf","executionInfo":{"status":"ok","timestamp":1735928655102,"user_tz":-330,"elapsed":24297,"user":{"displayName":"Rahul Gopalan","userId":"14909224090283081885"}},"outputId":"b8844b5d-c99f-4601-eabc-d94ccfc3a57d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["gemini - DONOT USE CAUSE WE WILL HAVE TO PAY I JUST LEFT IT FOR TESTING"],"metadata":{"id":"LVtR9KeAuxxd"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModel\n","from pathlib import Path\n","import fitz\n","import numpy as np\n","from dataclasses import dataclass\n","from typing import Dict, List, Tuple\n","import logging\n","import json\n","import google.generativeai as genai\n","import os\n","\n","@dataclass\n","class Paper:\n","    content: str\n","    path: Path\n","    is_reference: bool\n","    label: str = None\n","    conference: str = None\n","\n","class PaperClassifier:\n","    def __init__(self):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.conferences = [\"TMLR\", \"CVPR\", \"EMNLP\", \"NeurIPS\", \"KDD\"]\n","        self._setup_models()\n","\n","    def _setup_models(self):\n","        # Set up SciBERT\n","        self.scibert = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\").to(self.device)\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","        # Set up Gemini\n","        API_KEY = os.getenv(\"API_KEY\", \"KEY\")\n","        genai.configure(api_key=API_KEY)\n","\n","        # Create Gemini Pro model\n","        self.gemini = genai.GenerativeModel('gemini-pro')\n","\n","    def _generate_rationale(self, paper_content: str, is_publishable: bool, conference: str = None, scores: dict = None) -> str:\n","      if is_publishable:\n","          prompt = f\"\"\"\n","          Analyze this research paper for {conference} conference.\n","          Paper scores:\n","          - Technical similarity: {scores.get('technical', 0):.2f}\n","          - Methodology strength: {scores.get('method', 0):.2f}\n","          - Innovation level: {scores.get('innovation', 0):.2f}\n","\n","          Evaluate based on:\n","          1. Technical alignment with {conference}\n","          2. Research methodology quality\n","          3. Innovation and contribution value\n","\n","          Paper excerpt: {paper_content[:2000]}...\n","\n","          Provide a concise rationale (max 100 words) explaining why this paper should be published at {conference}:\n","          \"\"\"\n","      else:\n","          prompt = f\"\"\"\n","          Analyze this research paper that was classified as non-publishable.\n","          Paper scores:\n","          - Technical quality: {scores.get('technical', 0):.2f}\n","          - Methodology: {scores.get('method', 0):.2f}\n","          - Innovation: {scores.get('innovation', 0):.2f}\n","\n","          Evaluate critical issues in:\n","          1. Technical soundness\n","          2. Research methodology\n","          3. Novel contribution\n","\n","          Paper excerpt: {paper_content[:2000]}...\n","\n","          Provide a concise rationale (max 100 words) explaining why this paper needs improvement before publication:\n","          \"\"\"\n","\n","      try:\n","          response = self.gemini.generate_content(prompt)\n","          return response.text[:300].strip()\n","      except Exception as e:\n","          logging.error(f\"Error generating rationale: {e}\")\n","          return \"Error generating rationale\"\n","\n","    def load_dataset(self, base_path: str) -> Tuple[List[Paper], List[Paper]]:\n","        base_path = Path(base_path)\n","        reference_papers = []\n","        papers_to_classify = []\n","\n","        # Load reference papers\n","        ref_path = base_path / \"Reference\"\n","\n","        # Load publishable reference papers\n","        pub_path = ref_path / \"Publishable\"\n","        for conf in self.conferences:\n","            conf_path = pub_path / conf\n","            for pdf_path in conf_path.glob(\"*.pdf\"):\n","                content = self._extract_pdf_content(pdf_path)\n","                reference_papers.append(Paper(\n","                    content=content,\n","                    path=pdf_path,\n","                    is_reference=True,\n","                    label=\"Publishable\",\n","                    conference=conf\n","                ))\n","\n","        # Load non-publishable reference papers\n","        nonpub_path = ref_path / \"Non-Publishable\"\n","        for pdf_path in nonpub_path.glob(\"*.pdf\"):\n","            content = self._extract_pdf_content(pdf_path)\n","            reference_papers.append(Paper(\n","                content=content,\n","                path=pdf_path,\n","                is_reference=True,\n","                label=\"NonPublishable\"\n","            ))\n","\n","        # Load papers to classify\n","        papers_path = base_path / \"Papers\"\n","        for pdf_path in papers_path.glob(\"*.pdf\"):\n","            content = self._extract_pdf_content(pdf_path)\n","            papers_to_classify.append(Paper(\n","                content=content,\n","                path=pdf_path,\n","                is_reference=False\n","            ))\n","\n","        return reference_papers, papers_to_classify\n","\n","    def _extract_pdf_content(self, pdf_path: Path) -> str:\n","        try:\n","            doc = fitz.open(pdf_path)\n","            text = \"\"\n","            for page in doc:\n","                text += page.get_text()\n","            return text.strip()\n","        except Exception as e:\n","            logging.error(f\"Error extracting content from {pdf_path}: {e}\")\n","            return \"\"\n","\n","    def _setup_models(self):\n","        try:\n","            self.scibert = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\").to(self.device)\n","            self.tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","            self.tokenizer.pad_token = self.tokenizer.eos_token\n","            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n","\n","            # Set up Gemini\n","            API_KEY = os.getenv(\"API_KEY\", \"AIzaSyABSVGA83cLKJ-RhSFFbzMJkzG3aYE_YWE\")\n","            genai.configure(api_key=API_KEY)\n","            self.gemini = genai.GenerativeModel('gemini-pro')\n","        except Exception as e:\n","            logging.error(f\"Error setting up models: {e}\")\n","            raise\n","\n","    def _get_embedding(self, text: str) -> torch.Tensor:\n","        if not text or not isinstance(text, str):\n","            raise ValueError(\"Invalid input text for embedding generation\")\n","\n","        try:\n","            inputs = self.tokenizer(\n","                text,\n","                max_length=512,\n","                truncation=True,\n","                padding='max_length',\n","                return_tensors=\"pt\",\n","                return_attention_mask=True\n","            )\n","\n","            # Move to device\n","            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n","\n","            with torch.no_grad():\n","                outputs = self.scibert(**inputs)\n","\n","            if outputs.last_hidden_state is None:\n","                raise ValueError(\"Model output is None\")\n","\n","            # Use attention mask for weighted mean\n","            mask = inputs['attention_mask'].unsqueeze(-1).expand(outputs.last_hidden_state.size())\n","            masked_embeddings = outputs.last_hidden_state * mask\n","            sum_embeddings = torch.sum(masked_embeddings, dim=1)\n","            sum_mask = torch.clamp(mask.sum(dim=1), min=1e-9)\n","            return sum_embeddings / sum_mask\n","\n","        except Exception as e:\n","            logging.error(f\"Error generating embedding: {e}\")\n","            raise\n","\n","    def _cosine_similarity(self, a: torch.Tensor, b: torch.Tensor) -> float:\n","        return torch.cosine_similarity(a, b, dim=1).cpu().numpy()[0]\n","\n","    def classify_papers(self, reference_papers: List[Paper], papers: List[Paper]) -> List[Dict]:\n","        results = []\n","        ref_embeddings = {\n","            \"publishable\": [],\n","            \"conferences\": {},\n","            \"nonpublishable\": []\n","        }\n","\n","        # Validate inputs\n","        if not reference_papers or not papers:\n","            raise ValueError(\"Empty input papers list\")\n","\n","        # Process reference papers\n","        try:\n","            for ref in reference_papers:\n","                if not ref.content:\n","                    logging.warning(f\"Empty content in reference paper: {ref.path}\")\n","                    continue\n","\n","                emb = self._get_embedding(ref.content)\n","                if ref.label == \"Publishable\":\n","                    ref_embeddings[\"publishable\"].append(emb)\n","                    if ref.conference not in ref_embeddings[\"conferences\"]:\n","                        ref_embeddings[\"conferences\"][ref.conference] = []\n","                    ref_embeddings[\"conferences\"][ref.conference].append(emb)\n","                else:\n","                    ref_embeddings[\"nonpublishable\"].append(emb)\n","        except Exception as e:\n","            logging.error(f\"Error processing reference papers: {e}\")\n","            raise\n","\n","        # Process papers to classify\n","        for paper in papers:\n","            try:\n","                if not paper.content:\n","                    raise ValueError(f\"Empty content in paper: {paper.path}\")\n","\n","                emb = self._get_embedding(paper.content)\n","\n","                pub_scores = [self._cosine_similarity(emb, ref) for ref in ref_embeddings[\"publishable\"]]\n","                nonpub_scores = [self._cosine_similarity(emb, ref) for ref in ref_embeddings[\"nonpublishable\"]]\n","\n","                # Add threshold and weighting\n","                pub_threshold = 0.65\n","                is_publishable = (np.mean(pub_scores) * 1.2) > np.mean(nonpub_scores) and np.mean(pub_scores) > pub_threshold\n","\n","                scores = {\n","                    'technical': np.mean(pub_scores),\n","                    'method': np.max(pub_scores),\n","                    'innovation': np.mean(pub_scores) if is_publishable else np.mean(nonpub_scores)\n","                }\n","\n","                if is_publishable:\n","                    conf_scores = {\n","                        conf: np.mean([self._cosine_similarity(emb, ref) for ref in refs])\n","                        for conf, refs in ref_embeddings[\"conferences\"].items()\n","                    }\n","                    best_conf = max(conf_scores.items(), key=lambda x: x[1])[0]\n","\n","                    rationale = self._generate_rationale(paper.content, True, best_conf, scores)\n","\n","                    results.append({\n","                        \"paper_id\": paper.path.stem,\n","                        \"publishable\": 1,\n","                        \"conference\": best_conf,\n","                        \"rationale\": rationale\n","                    })\n","                else:\n","                    rationale = self._generate_rationale(paper.content, False, scores=scores)\n","                    results.append({\n","                        \"paper_id\": paper.path.stem,\n","                        \"publishable\": 0,\n","                        \"conference\": \"na\",\n","                        \"rationale\": rationale\n","                    })\n","\n","            except Exception as e:\n","                logging.error(f\"Error processing paper {paper.path}: {e}\")\n","                results.append({\n","                    \"paper_id\": paper.path.stem,\n","                    \"publishable\": 0,\n","                    \"conference\": \"error\",\n","                    \"rationale\": f\"Error: {str(e)}\"\n","                })\n","\n","        return results\n","\n","    def save_results_csv(self, results: List[Dict], output_path: str = \"results.csv\"):\n","        import pandas as pd\n","        df = pd.DataFrame(results)\n","        df.to_csv(output_path, index=False)\n","        print(f\"Results saved to {output_path}\")\n","\n","def main():\n","    # Configure logging\n","    logging.basicConfig(level=logging.INFO)\n","\n","    classifier = PaperClassifier()\n","    reference_papers, papers = classifier.load_dataset(\"/content/drive/MyDrive/KDSH_2025_Dataset\")\n","    results = classifier.classify_papers(reference_papers, papers)\n","\n","    # Save results in both JSON and CSV formats\n","    with open(\"results.json\", \"w\") as f:\n","        json.dump(results, f, indent=2)\n","\n","    classifier.save_results_csv(results)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"DphOtEuwpzp1","colab":{"base_uri":"https://localhost:8080/","height":974},"executionInfo":{"status":"ok","timestamp":1735929655399,"user_tz":-330,"elapsed":380076,"user":{"displayName":"Rahul Gopalan","userId":"14909224090283081885"}},"outputId":"fb5f7617-bf34-4fa5-beea-169778a7888e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Error generating rationale: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: MEDIUM\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n","probability: NEGLIGIBLE\n",", category: HARM_CATEGORY_HATE_SPEECH\n","probability: NEGLIGIBLE\n",", category: HARM_CATEGORY_HARASSMENT\n","probability: NEGLIGIBLE\n",", category: HARM_CATEGORY_DANGEROUS_CONTENT\n","probability: MEDIUM\n","])\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 655.62ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 731.83ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 958.30ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 656.46ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 606.12ms\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 932.76ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 959.03ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 933.22ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1159.41ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 908.30ms\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 657.32ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 934.74ms\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 656.59ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 630.26ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 882.59ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 731.49ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 932.76ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 655.04ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 907.76ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 933.66ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 631.08ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n","WARNING:tornado.access:429 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 931.81ms\n","ERROR:root:Error generating rationale: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).\n"]},{"output_type":"stream","name":"stdout","text":["Results saved to results.csv\n"]}]},{"cell_type":"markdown","source":["PROMPT -1 WITH FLAN T5\n"],"metadata":{"id":"NWqZcWgNi_S_"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n","from pathlib import Path\n","import fitz\n","import numpy as np\n","from dataclasses import dataclass\n","from typing import Dict, List, Tuple\n","import logging\n","import json\n","\n","@dataclass\n","class Paper:\n","    content: str\n","    path: Path\n","    is_reference: bool\n","    label: str = None\n","    conference: str = None\n","\n","class PaperClassifier:\n","    def __init__(self):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.conferences = [\"TMLR\", \"CVPR\", \"EMNLP\", \"NeurIPS\", \"KDD\"]\n","        self._setup_models()\n","\n","    def _setup_models(self):\n","        # SciBERT for embeddings\n","        self.scibert = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\").to(self.device)\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","        # FLAN-T5 for rationale generation\n","        self.rationale_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\").to(self.device)\n","        self.rationale_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n","\n","    def _generate_rationale(self, paper_content: str, conference: str) -> str:\n","        # Create a structured prompt for the model\n","        prompt = (\n","            f\"Given this research paper abstract: {paper_content[:500]}...\\n\\n\"\n","            f\"Explain in 2-3 sentences why this paper would be suitable for the {conference} conference. \"\n","            \"Focus on the paper's main contribution and methodology.\"\n","        )\n","\n","        inputs = self.rationale_tokenizer(\n","            prompt,\n","            max_length=512,\n","            truncation=True,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        ).to(self.device)\n","\n","        with torch.no_grad():\n","            outputs = self.rationale_model.generate(\n","                input_ids=inputs.input_ids,\n","                attention_mask=inputs.attention_mask,\n","                max_length=150,\n","                num_return_sequences=1,\n","                temperature=0.7,\n","                do_sample=True,\n","                no_repeat_ngram_size=2,\n","                top_k=50,\n","                top_p=0.95\n","            )\n","\n","        rationale = self.rationale_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return rationale\n","\n","    def load_dataset(self, base_path: str) -> Tuple[List[Paper], List[Paper]]:\n","        # [Previous load_dataset implementation remains the same]\n","        base_path = Path(base_path)\n","        reference_papers = []\n","        papers_to_classify = []\n","\n","        # Load reference papers\n","        ref_path = base_path / \"Reference\"\n","\n","        # Load publishable reference papers\n","        pub_path = ref_path / \"Publishable\"\n","        for conf in self.conferences:\n","            conf_path = pub_path / conf\n","            for pdf_path in conf_path.glob(\"*.pdf\"):\n","                content = self._extract_pdf_content(pdf_path)\n","                reference_papers.append(Paper(\n","                    content=content,\n","                    path=pdf_path,\n","                    is_reference=True,\n","                    label=\"Publishable\",\n","                    conference=conf\n","                ))\n","\n","        # Load non-publishable reference papers\n","        nonpub_path = ref_path / \"Non-Publishable\"\n","        for pdf_path in nonpub_path.glob(\"*.pdf\"):\n","            content = self._extract_pdf_content(pdf_path)\n","            reference_papers.append(Paper(\n","                content=content,\n","                path=pdf_path,\n","                is_reference=True,\n","                label=\"NonPublishable\"\n","            ))\n","\n","        # Load papers to classify\n","        papers_path = base_path / \"Papers\"\n","        for pdf_path in papers_path.glob(\"*.pdf\"):\n","            content = self._extract_pdf_content(pdf_path)\n","            papers_to_classify.append(Paper(\n","                content=content,\n","                path=pdf_path,\n","                is_reference=False\n","            ))\n","\n","        return reference_papers, papers_to_classify\n","\n","    def _extract_pdf_content(self, pdf_path: Path) -> str:\n","        try:\n","            doc = fitz.open(pdf_path)\n","            text = \"\"\n","            for page in doc:\n","                text += page.get_text()\n","            return text.strip()\n","        except Exception as e:\n","            logging.error(f\"Error extracting content from {pdf_path}: {e}\")\n","            return \"\"\n","\n","    def _get_embedding(self, text: str) -> torch.Tensor:\n","        inputs = self.tokenizer(\n","            text,\n","            max_length=512,\n","            truncation=True,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        ).to(self.device)\n","\n","        with torch.no_grad():\n","            outputs = self.scibert(**inputs)\n","        return outputs.last_hidden_state.mean(dim=1)\n","\n","    def _cosine_similarity(self, a: torch.Tensor, b: torch.Tensor) -> float:\n","        return torch.cosine_similarity(a, b, dim=1).cpu().numpy()[0]\n","\n","    def classify_papers(self, reference_papers: List[Paper], papers: List[Paper]) -> List[Dict]:\n","        results = []\n","        ref_embeddings = {\n","            \"publishable\": [],\n","            \"conferences\": {},\n","            \"nonpublishable\": []\n","        }\n","\n","        # Prepare reference embeddings\n","        for ref in reference_papers:\n","            emb = self._get_embedding(ref.content)\n","            if ref.label == \"Publishable\":\n","                ref_embeddings[\"publishable\"].append(emb)\n","                if ref.conference not in ref_embeddings[\"conferences\"]:\n","                    ref_embeddings[\"conferences\"][ref.conference] = []\n","                ref_embeddings[\"conferences\"][ref.conference].append(emb)\n","            else:\n","                ref_embeddings[\"nonpublishable\"].append(emb)\n","\n","        for paper in papers:\n","            try:\n","                emb = self._get_embedding(paper.content)\n","\n","                pub_scores = [self._cosine_similarity(emb, ref) for ref in ref_embeddings[\"publishable\"]]\n","                nonpub_scores = [self._cosine_similarity(emb, ref) for ref in ref_embeddings[\"nonpublishable\"]]\n","\n","                is_publishable = np.mean(pub_scores) > np.mean(nonpub_scores)\n","\n","                if is_publishable:\n","                    conf_scores = {}\n","                    for conf, conf_embs in ref_embeddings[\"conferences\"].items():\n","                        scores = [self._cosine_similarity(emb, ref) for ref in conf_embs]\n","                        conf_scores[conf] = np.mean(scores)\n","\n","                    best_conf = max(conf_scores.items(), key=lambda x: x[1])[0]\n","                    rationale = self._generate_rationale(paper.content, best_conf)\n","\n","                    results.append({\n","                        \"paper_id\": paper.path.stem,\n","                        \"publishable\": 1,\n","                        \"conference\": best_conf,\n","                        \"rationale\": rationale\n","                    })\n","                else:\n","                    results.append({\n","                        \"paper_id\": paper.path.stem,\n","                        \"publishable\": 0,\n","                        \"conference\": \"na\",\n","                        \"rationale\": \"na\"\n","                    })\n","\n","            except Exception as e:\n","                logging.error(f\"Error processing {paper.path}: {e}\")\n","                results.append({\n","                    \"paper_id\": paper.path.stem,\n","                    \"publishable\": 0,\n","                    \"conference\": \"error\",\n","                    \"rationale\": str(e)\n","                })\n","\n","        return results\n","\n","def main():\n","    classifier = PaperClassifier()\n","    reference_papers, papers = classifier.load_dataset(\"/content/drive/MyDrive/KDSH_2025_Dataset\")\n","    results = classifier.classify_papers(reference_papers, papers)\n","\n","    with open(\"results.json\", \"w\") as f:\n","        json.dump(results, f, indent=2)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241,"referenced_widgets":["a0ba8dde1c6646ec910c532e892ba415","3b28346374fa4ad582243b00ec4702ab","4db2f7a338b94b8eaa078872538a9913","adddf993a09f432081f22c2a66f9181b","b5e1f351df83452daf5b2d0d10280ce7","1ea2e73cf8fd4e698c45695abb8522ea","9dd6553a9c334078a1b4c2de6c89d69d","f36b6ccf150943f5af9d3302061de0ec","4fe3df4e5b934452b85f492262ebc5e4","d87082c6493643f6909d55a70eca89f6","8d5ad049b45048038207eda112819843","35e1183cb0b641839d0dc363e29a39d0","ad6fd4c36d694b3daf827ed1a5912743","5082d36da22b45a6bf7cbe7e907905c5","19e394bb9dd4468b9f44d12102dfca0d","e2f4a9fbb98d4250aad35dc264bbb706","b4fbae0377be43e883ae3bc12962b84a","3def0fd5ed9a4fe8912a417f2cb56a26","9634cb7bf7b745b2a98e9ce4e2113a3e","59f2d02f420d43029d670383a9970bee","c54297a148294564a830eb43d0f2c4b1","44e18f28daa54b36bb32e521c8a65338","661254c18a8246c199749007b058964f","21eb8eb96fdb47a8ba794121bf02323a","5abdd351905e441da9bdbad72a894b17","66712e90d0064cb0847eec7b6ffc337b","dd2b864e6b174994831b3785c32acf05","9cac865ba8db49a2a669c82326cd5ee2","2657c9f61911473bb22b1a1ce0adcf17","3aa893f761ca481fbae4443338114c23","3f0ceced2016466fb0b819d7ae31d489","bcaed63142e1476b8eff4ab36eedfe08","7c648ffd1b0947f9b609f829c2d38822","3c9ff15a5d5241258cb849a9be759189","54b33c924ee941c0961406b87862dfb5","97c92f024a7d4f499b2b02fc9e36fad9","8b0ebd4a25614e8e92c84d0b5f99839f","5b97871f23b44f3592be9a0922432295","e000ef3ca6d44bb9a5c4c340d0de76fb","1fe82d4b328845c0987b16cf45cf3383","bf38445015514fdda15a26f674311c2f","8202a6de43ac4692962f499e18e8165c","376c1336105e40478f52487d13e74d73","82e41547e60e475782e9663a402497f6","32f9c3e6c2df431d93d4ebf9095af0c8","1a82cf3769104ca98d8ed81be6d30f17","a5301d236b594b0eabc4be6374915bdc","fc6636acc6cd4b01b23e31da90ad2d70","e5a0869e73b241e99e6d397ad77a2620","ed1ace2e997445b78165581e4ffa7751","18f4243abc724103a963741045b2f3a2","fdf7137320ec4af9879c58088b5f5ab6","cf196d5f57864586adc988dbd2a57a24","01a1a5a68e4f45f6aeacbb0711cccfcb","6ceb0661d55b4dfaa931c917d865aec3","afc1bbbe574f40c0aa99e92498b3062f","914b6ecb1b9b4fcbaccf8013340caa82","36766b8751534f309ad9e7f483cdafbe","00ad5a8479654528a18b3b90f1c299d4","bbea0bf76fd0414b832b065faec5c9c3","54d02d0b1191490ca76dc4eb9a834956","3713051e481f4fb785bc9291ca7cc701","467291599826467ea4965afbd94a2f1d","109fa126706a46469ee4ac4ceb92dc52","ce0359c275404c838ecf9d9c30f44754","922cde49f8194be88a1f652908b0fd9b","8e586c051a7e49d4a8464f1a74a8393c","7b9ed184fdf5436186ee590dfca7b2e9","dfd73b6968434c3f92a28d95c2739eb6","40ec16594cc74a8d9e1cdd93355a82d1","23f7bb2cdbeb400fa96eaa71247e22c2","752bb933b9e04e3ea80188b250bd4202","cae919e8e9ed4e37a59818a6fce25fec","79d77be0dad245b685353783e32faf59","4e6a056a44324dca8b89fa99884acb55","41ee7cbf144d499c83677f4fc1ac64b3","905fc9e19838460e83ae78f6ca1de355"]},"id":"6wS_xDRNae8B","executionInfo":{"status":"ok","timestamp":1735930538422,"user_tz":-330,"elapsed":107618,"user":{"displayName":"Rahul Gopalan","userId":"14909224090283081885"}},"outputId":"43abbda2-a2e6-40f4-f2a6-f9600f92e4b0"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0ba8dde1c6646ec910c532e892ba415"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e1183cb0b641839d0dc363e29a39d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"661254c18a8246c199749007b058964f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c9ff15a5d5241258cb849a9be759189"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f9c3e6c2df431d93d4ebf9095af0c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc1bbbe574f40c0aa99e92498b3062f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e586c051a7e49d4a8464f1a74a8393c"}},"metadata":{}}]},{"cell_type":"markdown","source":["PROMPT 2 WITH FLAN-T5"],"metadata":{"id":"WT0L2955jJ6L"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n","from pathlib import Path\n","import fitz\n","import numpy as np\n","from dataclasses import dataclass\n","from typing import Dict, List, Tuple\n","import logging\n","import json\n","\n","@dataclass\n","class Paper:\n","    content: str\n","    path: Path\n","    is_reference: bool\n","    label: str = None\n","    conference: str = None\n","\n","class PaperClassifier:\n","    def __init__(self):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.conferences = [\"TMLR\", \"CVPR\", \"EMNLP\", \"NeurIPS\", \"KDD\"]\n","        self._setup_models()\n","\n","    def _setup_models(self):\n","        # SciBERT for embeddings\n","        self.scibert = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\").to(self.device)\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","        # FLAN-T5 for rationale generation\n","        self.rationale_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\").to(self.device)\n","        self.rationale_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n","\n","    def _generate_rationale(self, paper_content: str, conference: str) -> str:\n","         # Create a more targeted prompt that addresses conference fit\n","        conference_descriptions = {\n","            \"CVPR\": \"Computer Vision and Pattern Recognition - focuses on computer vision, deep learning for visual tasks, and image processing innovations\",\n","            \"NeurIPS\": \"Neural Information Processing Systems - emphasizes machine learning, neural networks, and artificial intelligence advances\",\n","            \"EMNLP\": \"Empirical Methods in Natural Language Processing - centers on NLP, computational linguistics, and language understanding\",\n","            \"TMLR\": \"Transactions on Machine Learning Research - covers broad machine learning research with emphasis on thorough empirical validation\",\n","            \"KDD\": \"Knowledge Discovery and Data Mining - focuses on data mining, large-scale data analytics, and practical applications\"\n","        }\n","\n","        prompt = (\n","            f\"Analyze this research paper and explain its suitability for {conference} conference.\\n\\n\"\n","            f\"Conference scope: {conference_descriptions[conference]}\\n\\n\"\n","            f\"Paper abstract: {paper_content[:500]}...\\n\\n\"\n","            \"Provide a 2-3 sentence rationale that addresses:\\n\"\n","            \"1. How the paper's methodology and findings align with the conference's focus areas\\n\"\n","            \"2. The significance of the research contribution to the field\\n\"\n","            \"3. Why this specific conference is the most appropriate venue for this work\"\n","        )\n","\n","        inputs = self.rationale_tokenizer(\n","            prompt,\n","            max_length=512,\n","            truncation=True,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        ).to(self.device)\n","\n","        with torch.no_grad():\n","            outputs = self.rationale_model.generate(\n","                input_ids=inputs.input_ids,\n","                attention_mask=inputs.attention_mask,\n","                max_length=150,\n","                num_return_sequences=1,\n","                temperature=0.7,\n","                do_sample=True,\n","                no_repeat_ngram_size=2,\n","                top_k=50,\n","                top_p=0.95\n","            )\n","\n","        rationale = self.rationale_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return rationale\n","\n","    def load_dataset(self, base_path: str) -> Tuple[List[Paper], List[Paper]]:\n","        # [Previous load_dataset implementation remains the same]\n","        base_path = Path(base_path)\n","        reference_papers = []\n","        papers_to_classify = []\n","\n","        # Load reference papers\n","        ref_path = base_path / \"Reference\"\n","\n","        # Load publishable reference papers\n","        pub_path = ref_path / \"Publishable\"\n","        for conf in self.conferences:\n","            conf_path = pub_path / conf\n","            for pdf_path in conf_path.glob(\"*.pdf\"):\n","                content = self._extract_pdf_content(pdf_path)\n","                reference_papers.append(Paper(\n","                    content=content,\n","                    path=pdf_path,\n","                    is_reference=True,\n","                    label=\"Publishable\",\n","                    conference=conf\n","                ))\n","\n","        # Load non-publishable reference papers\n","        nonpub_path = ref_path / \"Non-Publishable\"\n","        for pdf_path in nonpub_path.glob(\"*.pdf\"):\n","            content = self._extract_pdf_content(pdf_path)\n","            reference_papers.append(Paper(\n","                content=content,\n","                path=pdf_path,\n","                is_reference=True,\n","                label=\"NonPublishable\"\n","            ))\n","\n","        # Load papers to classify\n","        papers_path = base_path / \"Papers\"\n","        for pdf_path in papers_path.glob(\"*.pdf\"):\n","            content = self._extract_pdf_content(pdf_path)\n","            papers_to_classify.append(Paper(\n","                content=content,\n","                path=pdf_path,\n","                is_reference=False\n","            ))\n","\n","        return reference_papers, papers_to_classify\n","\n","    def _extract_pdf_content(self, pdf_path: Path) -> str:\n","        try:\n","            doc = fitz.open(pdf_path)\n","            text = \"\"\n","            for page in doc:\n","                text += page.get_text()\n","            return text.strip()\n","        except Exception as e:\n","            logging.error(f\"Error extracting content from {pdf_path}: {e}\")\n","            return \"\"\n","\n","    def _get_embedding(self, text: str) -> torch.Tensor:\n","        inputs = self.tokenizer(\n","            text,\n","            max_length=512,\n","            truncation=True,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        ).to(self.device)\n","\n","        with torch.no_grad():\n","            outputs = self.scibert(**inputs)\n","        return outputs.last_hidden_state.mean(dim=1)\n","\n","    def _cosine_similarity(self, a: torch.Tensor, b: torch.Tensor) -> float:\n","        return torch.cosine_similarity(a, b, dim=1).cpu().numpy()[0]\n","\n","    def classify_papers(self, reference_papers: List[Paper], papers: List[Paper]) -> List[Dict]:\n","        results = []\n","        ref_embeddings = {\n","            \"publishable\": [],\n","            \"conferences\": {},\n","            \"nonpublishable\": []\n","        }\n","\n","        # Prepare reference embeddings\n","        for ref in reference_papers:\n","            emb = self._get_embedding(ref.content)\n","            if ref.label == \"Publishable\":\n","                ref_embeddings[\"publishable\"].append(emb)\n","                if ref.conference not in ref_embeddings[\"conferences\"]:\n","                    ref_embeddings[\"conferences\"][ref.conference] = []\n","                ref_embeddings[\"conferences\"][ref.conference].append(emb)\n","            else:\n","                ref_embeddings[\"nonpublishable\"].append(emb)\n","\n","        for paper in papers:\n","            try:\n","                emb = self._get_embedding(paper.content)\n","\n","                pub_scores = [self._cosine_similarity(emb, ref) for ref in ref_embeddings[\"publishable\"]]\n","                nonpub_scores = [self._cosine_similarity(emb, ref) for ref in ref_embeddings[\"nonpublishable\"]]\n","\n","                is_publishable = np.mean(pub_scores) > np.mean(nonpub_scores)\n","\n","                if is_publishable:\n","                    conf_scores = {}\n","                    for conf, conf_embs in ref_embeddings[\"conferences\"].items():\n","                        scores = [self._cosine_similarity(emb, ref) for ref in conf_embs]\n","                        conf_scores[conf] = np.mean(scores)\n","\n","                    best_conf = max(conf_scores.items(), key=lambda x: x[1])[0]\n","                    rationale = self._generate_rationale(paper.content, best_conf)\n","\n","                    results.append({\n","                        \"paper_id\": paper.path.stem,\n","                        \"publishable\": 1,\n","                        \"conference\": best_conf,\n","                        \"rationale\": rationale\n","                    })\n","                else:\n","                    results.append({\n","                        \"paper_id\": paper.path.stem,\n","                        \"publishable\": 0,\n","                        \"conference\": \"na\",\n","                        \"rationale\": \"na\"\n","                    })\n","\n","            except Exception as e:\n","                logging.error(f\"Error processing {paper.path}: {e}\")\n","                results.append({\n","                    \"paper_id\": paper.path.stem,\n","                    \"publishable\": 0,\n","                    \"conference\": \"error\",\n","                    \"rationale\": str(e)\n","                })\n","\n","        return results\n","\n","def main():\n","    classifier = PaperClassifier()\n","    reference_papers, papers = classifier.load_dataset(\"/content/drive/MyDrive/KDSH_2025_Dataset\")\n","    results = classifier.classify_papers(reference_papers, papers)\n","\n","    with open(\"results.json\", \"w\") as f:\n","        json.dump(results, f, indent=2)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"5vFjV5oagbf5","executionInfo":{"status":"ok","timestamp":1735931247860,"user_tz":-330,"elapsed":166240,"user":{"displayName":"Rahul Gopalan","userId":"14909224090283081885"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["PROMPT 3 FLANT T5\n"],"metadata":{"id":"iMISJO4Mm7I0"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n","from pathlib import Path\n","import fitz\n","import numpy as np\n","from dataclasses import dataclass\n","from typing import Dict, List, Tuple\n","import logging\n","import json\n","\n","@dataclass\n","class Paper:\n","    content: str\n","    path: Path\n","    is_reference: bool\n","    label: str = None\n","    conference: str = None\n","\n","class PaperClassifier:\n","    def __init__(self):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.conferences = [\"TMLR\", \"CVPR\", \"EMNLP\", \"NeurIPS\", \"KDD\"]\n","        self._setup_models()\n","\n","    def _setup_models(self):\n","        # SciBERT for embeddings\n","        self.scibert = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\").to(self.device)\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n","\n","        # FLAN-T5 for rationale generation\n","        self.rationale_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\").to(self.device)\n","        self.rationale_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n","\n","    def _generate_rationale(self, paper_content: str, conference: str) -> str:\n","         # Create a more targeted prompt that addresses conference fit\n","        conference_descriptions = {\n","            \"CVPR\": \"Computer Vision and Pattern Recognition - focuses on computer vision, deep learning for visual tasks, and image processing innovations\",\n","            \"NeurIPS\": \"Neural Information Processing Systems - emphasizes machine learning, neural networks, and artificial intelligence advances\",\n","            \"EMNLP\": \"Empirical Methods in Natural Language Processing - centers on NLP, computational linguistics, and language understanding\",\n","            \"TMLR\": \"Transactions on Machine Learning Research - covers broad machine learning research with emphasis on thorough empirical validation\",\n","            \"KDD\": \"Knowledge Discovery and Data Mining - focuses on data mining, large-scale data analytics, and practical applications\"\n","        }\n","\n","        prompt = (\n","            f\"Analyze this research paper and explain its suitability for {conference} conference.\\n\\n\"\n","            f\"Conference scope: {conference_descriptions[conference]}\\n\\n\"\n","            f\"Paper abstract: {paper_content[:500]}...\\n\\n\"\n","            \"Provide a 2-3 sentence rationale that addresses:\\n\"\n","            \"1. How the paper's methodology and findings align with the conference's focus areas\\n\"\n","            \"2. The significance of the research contribution to the field\\n\"\n","            \"3. Why this specific conference is the most appropriate venue for this work\"\n","        )\n","\n","        inputs = self.rationale_tokenizer(\n","            prompt,\n","            max_length=512,\n","            truncation=True,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        ).to(self.device)\n","\n","        with torch.no_grad():\n","            outputs = self.rationale_model.generate(\n","                input_ids=inputs.input_ids,\n","                attention_mask=inputs.attention_mask,\n","                max_length=150,\n","                num_return_sequences=1,\n","                temperature=0.7,\n","                do_sample=True,\n","                no_repeat_ngram_size=2,\n","                top_k=50,\n","                top_p=0.95\n","            )\n","\n","        rationale = self.rationale_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return rationale\n","\n","    def load_dataset(self, base_path: str) -> Tuple[List[Paper], List[Paper]]:\n","        # [Previous load_dataset implementation remains the same]\n","        base_path = Path(base_path)\n","        reference_papers = []\n","        papers_to_classify = []\n","\n","        # Load reference papers\n","        ref_path = base_path / \"Reference\"\n","\n","        # Load publishable reference papers\n","        pub_path = ref_path / \"Publishable\"\n","        for conf in self.conferences:\n","            conf_path = pub_path / conf\n","            for pdf_path in conf_path.glob(\"*.pdf\"):\n","                content = self._extract_pdf_content(pdf_path)\n","                reference_papers.append(Paper(\n","                    content=content,\n","                    path=pdf_path,\n","                    is_reference=True,\n","                    label=\"Publishable\",\n","                    conference=conf\n","                ))\n","\n","        # Load non-publishable reference papers\n","        nonpub_path = ref_path / \"Non-Publishable\"\n","        for pdf_path in nonpub_path.glob(\"*.pdf\"):\n","            content = self._extract_pdf_content(pdf_path)\n","            reference_papers.append(Paper(\n","                content=content,\n","                path=pdf_path,\n","                is_reference=True,\n","                label=\"NonPublishable\"\n","            ))\n","\n","        # Load papers to classify\n","        papers_path = base_path / \"Papers\"\n","        for pdf_path in papers_path.glob(\"*.pdf\"):\n","            content = self._extract_pdf_content(pdf_path)\n","            papers_to_classify.append(Paper(\n","                content=content,\n","                path=pdf_path,\n","                is_reference=False\n","            ))\n","\n","        return reference_papers, papers_to_classify\n","\n","    def _extract_pdf_content(self, pdf_path: Path) -> str:\n","        try:\n","            doc = fitz.open(pdf_path)\n","            text = \"\"\n","            for page in doc:\n","                text += page.get_text()\n","            return text.strip()\n","        except Exception as e:\n","            logging.error(f\"Error extracting content from {pdf_path}: {e}\")\n","            return \"\"\n","\n","    def _get_embedding(self, text: str) -> torch.Tensor:\n","        inputs = self.tokenizer(\n","            text,\n","            max_length=512,\n","            truncation=True,\n","            padding=True,\n","            return_tensors=\"pt\"\n","        ).to(self.device)\n","\n","        with torch.no_grad():\n","            outputs = self.scibert(**inputs)\n","        return outputs.last_hidden_state.mean(dim=1)\n","\n","    def _cosine_similarity(self, a: torch.Tensor, b: torch.Tensor) -> float:\n","        return torch.cosine_similarity(a, b, dim=1).cpu().numpy()[0]\n","\n","    def classify_papers(self, reference_papers: List[Paper], papers: List[Paper]) -> List[Dict]:\n","        results = []\n","        ref_embeddings = {\n","            \"publishable\": [],\n","            \"conferences\": {},\n","            \"nonpublishable\": []\n","        }\n","\n","        # Prepare reference embeddings\n","        for ref in reference_papers:\n","            emb = self._get_embedding(ref.content)\n","            if ref.label == \"Publishable\":\n","                ref_embeddings[\"publishable\"].append(emb)\n","                if ref.conference not in ref_embeddings[\"conferences\"]:\n","                    ref_embeddings[\"conferences\"][ref.conference] = []\n","                ref_embeddings[\"conferences\"][ref.conference].append(emb)\n","            else:\n","                ref_embeddings[\"nonpublishable\"].append(emb)\n","\n","        for paper in papers:\n","            try:\n","                emb = self._get_embedding(paper.content)\n","\n","                pub_scores = [self._cosine_similarity(emb, ref) for ref in ref_embeddings[\"publishable\"]]\n","                nonpub_scores = [self._cosine_similarity(emb, ref) for ref in ref_embeddings[\"nonpublishable\"]]\n","\n","                is_publishable = np.mean(pub_scores) > np.mean(nonpub_scores)\n","\n","                if is_publishable:\n","                    conf_scores = {}\n","                    for conf, conf_embs in ref_embeddings[\"conferences\"].items():\n","                        scores = [self._cosine_similarity(emb, ref) for ref in conf_embs]\n","                        conf_scores[conf] = np.mean(scores)\n","\n","                    best_conf = max(conf_scores.items(), key=lambda x: x[1])[0]\n","                    rationale = self._generate_rationale(paper.content, best_conf)\n","\n","                    results.append({\n","                        \"paper_id\": paper.path.stem,\n","                        \"publishable\": 1,\n","                        \"conference\": best_conf,\n","                        \"rationale\": rationale\n","                    })\n","                else:\n","                    results.append({\n","                        \"paper_id\": paper.path.stem,\n","                        \"publishable\": 0,\n","                        \"conference\": \"na\",\n","                        \"rationale\": \"na\"\n","                    })\n","\n","            except Exception as e:\n","                logging.error(f\"Error processing {paper.path}: {e}\")\n","                results.append({\n","                    \"paper_id\": paper.path.stem,\n","                    \"publishable\": 0,\n","                    \"conference\": \"error\",\n","                    \"rationale\": str(e)\n","                })\n","\n","        return results\n","\n","def main():\n","    classifier = PaperClassifier()\n","    reference_papers, papers = classifier.load_dataset(\"/content/drive/MyDrive/KDSH_2025_Dataset\")\n","    results = classifier.classify_papers(reference_papers, papers)\n","\n","    with open(\"results.json\", \"w\") as f:\n","        json.dump(results, f, indent=2)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"Q0yWDBbgm9lX"},"execution_count":null,"outputs":[]}]}